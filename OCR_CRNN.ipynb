{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aBmqtjdlM99A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4214e391"
      },
      "source": [
        "# Task\n",
        "Sajikan ringkasan hasil pelatihan dan evaluasi model OCR CRNN, beserta insight tentang kinerjanya dalam mengenali urutan digit MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10b012bf"
      },
      "source": [
        "## Persiapan Data MNIST\n",
        "\n",
        "### Subtask:\n",
        "Muat dataset MNIST dan lakukan preprocessing dasar seperti normalisasi pixel serta pembagian menjadi set pelatihan dan validasi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad43f6ea"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll import TensorFlow and Keras to load the MNIST dataset. Then I'll load the MNIST dataset using `tf.keras.datasets.mnist.load_data()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbe8fd9c",
        "outputId": "99f7a263-e1e7-4f6b-ea15-461271ecf407"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(f\"Original training data shape: {x_train.shape}\")\n",
        "print(f\"Original testing data shape: {x_test.shape}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Original training data shape: (60000, 28, 28)\n",
            "Original testing data shape: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1413dca8"
      },
      "source": [
        "**Reasoning**:\n",
        "Now I will normalize the pixel values of the MNIST images to a range of [0, 1] and reshape them to include a channel dimension, as specified in the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da25acf8",
        "outputId": "49e8a1ef-e418-4b0c-c418-dcc2386dc95a"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "print(f\"Normalized and reshaped training data shape: {x_train.shape}\")\n",
        "print(f\"Normalized and reshaped testing data shape: {x_test.shape}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized and reshaped training data shape: (60000, 28, 28, 1)\n",
            "Normalized and reshaped testing data shape: (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "026657a9"
      },
      "source": [
        "## Pembuatan Data Sintetis untuk CRNN\n",
        "\n",
        "### Subtask:\n",
        "Buat data gambar sintetik dengan menggabungkan beberapa gambar digit MNIST menjadi satu gambar panjang, dan buat label urutan yang sesuai untuk melatih model CRNN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebf30150"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining a `max_sequence_length` and then creating a function `create_synthetic_data` to generate synthetic images and their corresponding sequence labels from the MNIST dataset. This function will select random digits, combine their images horizontally, and create padded labels. Finally, the function will be called for both training and test sets and the shapes of the generated data will be printed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91224dd6",
        "outputId": "2d668322-7b0e-474d-e97c-d405a2c606d4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Definisikan max_sequence_length\n",
        "max_sequence_length = 5\n",
        "\n",
        "# 2. Definisikan fungsi, misalnya create_synthetic_data\n",
        "def create_synthetic_data(x_data, y_data, num_samples, max_sequence_length, original_image_width=28):\n",
        "    synthetic_images = []\n",
        "    synthetic_labels = []\n",
        "    blank_char = 10  # Represent 'blank' digit, since MNIST digits are 0-9\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # i. Secara acak pilih jumlah digit untuk digabungkan\n",
        "        current_sequence_length = np.random.randint(1, max_sequence_length + 1)\n",
        "\n",
        "        # ii. Secara acak pilih sejumlah gambar digit MNIST dan labelnya yang sesuai\n",
        "        # Ensure we have enough unique indices to pick digits\n",
        "        indices = np.random.choice(len(x_data), current_sequence_length, replace=False)\n",
        "        selected_images = x_data[indices]\n",
        "        selected_labels = y_data[indices]\n",
        "\n",
        "        # iii. Gabungkan gambar-gambar digit yang dipilih secara horizontal\n",
        "        # Initialize an empty canvas for the synthetic image\n",
        "        synthetic_image_width = max_sequence_length * original_image_width\n",
        "        combined_image = np.zeros((original_image_width, synthetic_image_width, 1), dtype=np.float32)\n",
        "\n",
        "        # Place selected images onto the canvas\n",
        "        current_x_offset = 0\n",
        "        for img in selected_images:\n",
        "            # Remove channel dimension temporarily to concatenate\n",
        "            img_2d = img.squeeze()\n",
        "            combined_image[:, current_x_offset:current_x_offset + original_image_width, 0] = img_2d\n",
        "            current_x_offset += original_image_width\n",
        "\n",
        "        synthetic_images.append(combined_image)\n",
        "\n",
        "        # iv. Gabungkan label digit yang dipilih dan tambahkan karakter 'kosong'\n",
        "        sequence_label = list(selected_labels)\n",
        "        # Pad with blank_char to reach max_sequence_length\n",
        "        sequence_label.extend([blank_char] * (max_sequence_length - current_sequence_length))\n",
        "        synthetic_labels.append(sequence_label)\n",
        "\n",
        "    # c. Konversi daftar menjadi array NumPy\n",
        "    synthetic_images = np.array(synthetic_images)\n",
        "    synthetic_labels = np.array(synthetic_labels)\n",
        "\n",
        "    # d. Kembalikan array gambar sintetik dan label urutan\n",
        "    return synthetic_images, synthetic_labels\n",
        "\n",
        "# 4. Panggil fungsi create_synthetic_data untuk set pelatihan dan validasi/pengujian\n",
        "num_train_samples = 50000\n",
        "num_test_samples = 10000\n",
        "\n",
        "print(f\"Generating {num_train_samples} training samples...\")\n",
        "synth_x_train, synth_y_train = create_synthetic_data(x_train, y_train, num_train_samples, max_sequence_length)\n",
        "print(f\"Generating {num_test_samples} testing samples...\")\n",
        "synth_x_test, synth_y_test = create_synthetic_data(x_test, y_test, num_test_samples, max_sequence_length)\n",
        "\n",
        "# 5. Cetak bentuk (shape) dari synth_x_train, synth_y_train, synth_x_test, dan synth_y_test\n",
        "print(f\"Shape of synthetic training images: {synth_x_train.shape}\")\n",
        "print(f\"Shape of synthetic training labels: {synth_y_train.shape}\")\n",
        "print(f\"Shape of synthetic testing images: {synth_x_test.shape}\")\n",
        "print(f\"Shape of synthetic testing labels: {synth_y_test.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 50000 training samples...\n",
            "Generating 10000 testing samples...\n",
            "Shape of synthetic training images: (50000, 28, 140, 1)\n",
            "Shape of synthetic training labels: (50000, 5)\n",
            "Shape of synthetic testing images: (10000, 28, 140, 1)\n",
            "Shape of synthetic testing labels: (10000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb30f6b7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `Model` was incorrectly imported from `tensorflow.keras.layers`. It should be imported directly from `tensorflow.keras`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "5d7cf34d",
        "outputId": "2a8c5a83-4623-47fb-8157-ed35b1dfba35"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Activation\n",
        "from tensorflow.keras import Model # Corrected import for Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# 2. Definisikan dimensi input\n",
        "# input_shape: (height, width, channels)\n",
        "input_shape = synth_x_train.shape[1:]\n",
        "img_height, img_width, img_channels = input_shape\n",
        "\n",
        "# Number of classes (0-9 digits + 1 for blank character)\n",
        "num_classes = 10 + 1\n",
        "\n",
        "# Input layer\n",
        "input_img = Input(shape=input_shape, name='image_input')\n",
        "\n",
        "# 3. Bangun bagian CNN dari model\n",
        "# Layer 1\n",
        "conv_1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "pool_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
        "\n",
        "# Layer 2\n",
        "conv_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool_1)\n",
        "pool_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
        "\n",
        "# Further convolutional layers to extract more features\n",
        "conv_3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool_2)\n",
        "pool_3 = MaxPooling2D(pool_size=(2, 1))(conv_3) # Pool only along height to preserve width for timesteps\n",
        "\n",
        "conv_4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool_3)\n",
        "pool_4 = MaxPooling2D(pool_size=(2, 1))(conv_4)\n",
        "\n",
        "# Calculate dimensions after CNN layers\n",
        "# Height will be reduced by 2*2*2*2 = 16 times in theory, but with (2,1) it's different\n",
        "# Let's check output shape dynamically or calculate carefully\n",
        "# Input height: 28\n",
        "# pool_1 height: 28/2 = 14\n",
        "# pool_2 height: 14/2 = 7\n",
        "# pool_3 height: 7/2 = 3 (integer division, might need adjustment for exact CRNN alignment, but Keras handles this)\n",
        "# pool_4 height: 3/2 = 1\n",
        "\n",
        "# Input width: 140\n",
        "# pool_1 width: 140/2 = 70\n",
        "# pool_2 width: 70/2 = 35\n",
        "# pool_3 width: 35/1 = 35\n",
        "# pool_4 width: 35/1 = 35\n",
        "\n",
        "# Get output shape from pool_4 to prepare for Reshape\n",
        "cnn_output_shape = K.int_shape(pool_4)\n",
        "# cnn_output_shape will be (None, height, width, channels)\n",
        "\n",
        "# Reshape for RNN: (batch, timesteps, features)\n",
        "# Timesteps will be the width of the CNN output\n",
        "# Features will be height * channels of the CNN output\n",
        "reshaped = Reshape(target_shape=(cnn_output_shape[2], cnn_output_shape[1] * cnn_output_shape[3]), name='reshape')(pool_4)\n",
        "\n",
        "# 4. Bangun bagian RNN dari model\n",
        "# Bidirectional LSTM layers\n",
        "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.25))(reshaped)\n",
        "blstm_2 = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25))(blstm_1)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(num_classes, name='dense_output')(blstm_2)\n",
        "output = Activation('softmax', name='softmax_output')(output)\n",
        "\n",
        "# 5. Buat model Keras\n",
        "model = Model(inputs=input_img, outputs=output)\n",
        "\n",
        "# 6. Cetak ringkasan model\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m394,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m164,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m11\u001b[0m)         │         \u001b[38;5;34m1,419\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax_output (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m11\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m947,851\u001b[0m (3.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">947,851</span> (3.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m947,851\u001b[0m (3.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">947,851</span> (3.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8f9026"
      },
      "source": [
        "## Kompilasi dan Pelatihan Model CRNN\n",
        "\n",
        "### Subtask:\n",
        "Kompilasi model dengan optimizer yang sesuai dan fungsi loss Connectionist Temporal Classification (CTC), yang umum digunakan untuk pengenalan urutan. Kemudian, latih model menggunakan data sintetik yang telah dibuat.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b64fc1a6"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining a custom CTC loss function, compiling the CRNN model with it, and then training the model. I will first define the `ctc_loss_func` that takes `y_true` and `y_pred` and internally uses `tf.keras.backend.ctc_batch_cost` with dynamically created `input_length` and `label_length` tensors based on the fixed output dimensions of the CNN and the `max_sequence_length`. Then, I will compile the `model` with this loss and an Adam optimizer. Finally, I will train the model using the synthetic training and testing data, specifying epochs and batch size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "815542c6",
        "outputId": "26c343e4-a1a1-41a8-fb8b-bee1c9af3dc4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Definisikan fungsi ctc_loss\n",
        "def ctc_loss_func(y_true, y_pred):\n",
        "    # y_true: (batch_size, max_sequence_length)\n",
        "    # y_pred: (batch_size, timesteps, num_classes)\n",
        "\n",
        "    # The input_length for CTC needs to be a tensor of shape (batch_size, 1)\n",
        "    # and contains the number of timesteps in y_pred for each sample.\n",
        "    # In our case, this is fixed by the CNN's output width (cnn_output_shape[2]).\n",
        "    batch_size = tf.shape(y_pred)[0]\n",
        "    input_length = tf.fill(dims=(batch_size, 1), value=cnn_output_shape[2]) # cnn_output_shape[2] is 35\n",
        "\n",
        "    # The label_length for CTC needs to be a tensor of shape (batch_size, 1)\n",
        "    # and contains the length of the true labels (max_sequence_length).\n",
        "    # In our case, this is fixed by max_sequence_length.\n",
        "    label_length = tf.fill(dims=(batch_size, 1), value=max_sequence_length) # max_sequence_length is 5\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n",
        "\n",
        "# 2. Compile model with Adam optimizer and ctc_loss_func\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss=ctc_loss_func)\n",
        "\n",
        "# 3. Latih model\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "print(\"Training the CRNN model...\")\n",
        "history = model.fit(\n",
        "    x=synth_x_train,\n",
        "    y=synth_y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(synth_x_test, synth_y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the CRNN model...\n",
            "Epoch 1/10\n",
            "\u001b[1m743/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 8.3229"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ec93a61"
      },
      "source": [
        "# Task\n",
        "Sajikan ringkasan hasil pelatihan dan evaluasi model OCR CRNN, beserta insight tentang kinerjanya dalam mengenali urutan digit MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6889691"
      },
      "source": [
        "## Evaluasi Model dan Prediksi\n",
        "\n",
        "### Subtask:\n",
        "Evaluasi kinerja model CRNN yang telah terlatih pada set data pengujian sintetik. Tampilkan contoh prediksi untuk melihat bagaimana model mengenali urutan digit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3150d5eb"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll define the `decode_batch_predictions` function. This function will take the model's predictions (which are in CTC output format) and use `tf.keras.backend.ctc_decode` to convert them into a readable sequence of digits. It will also convert the sparse tensor output of `ctc_decode` into a dense NumPy array, which is easier to work with for display purposes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92578c6e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 1. Definisikan fungsi decode_batch_predictions\n",
        "def decode_batch_predictions(pred):\n",
        "    # Use ctc_decode to get the decoded sequences. `greedy=False` for beam search if needed,\n",
        "    # but for simplicity, `greedy=True` is often used first.\n",
        "    # The second return value is the log-probability of the sequence, which we don't need for this task.\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "\n",
        "    # Convert sparse tensor to dense numpy array. Pad with `blank_char` (10) if the decoded sequence is shorter than max_sequence_length\n",
        "    decoded_sequences = tf.sparse.to_dense(results, default_value=blank_char).numpy()\n",
        "    return decoded_sequences\n",
        "\n",
        "# Note: `blank_char` (10) and `max_sequence_length` (5) are already defined from previous steps."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f2580d0"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `decode_batch_predictions` function is defined, I will perform predictions on the test set, decode these predictions, create a mapping for digit representation, and then visualize 10 random examples from the test set, showing the synthetic image, actual label, and predicted label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "702e15c2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2. Lakukan prediksi pada synth_x_test\n",
        "predictions = model.predict(synth_x_test)\n",
        "\n",
        "# 3. Gunakan fungsi decode_batch_predictions untuk mendekode predictions\n",
        "decoded_predictions = decode_batch_predictions(predictions)\n",
        "\n",
        "# 4. Definisikan pemetaan dari indeks digit ke karakter yang sesuai\n",
        "digit_to_char = {i: str(i) for i in range(10)}\n",
        "digit_to_char[blank_char] = '_'\n",
        "\n",
        "def labels_to_string(labels):\n",
        "    return ''.join([digit_to_char[digit] for digit in labels if digit != blank_char])\n",
        "\n",
        "# 5. Ambil 10 contoh acak dari set pengujian dan tampilkan\n",
        "print(\"Displaying 10 random examples from the test set:\\n\")\n",
        "\n",
        "num_examples_to_display = 10\n",
        "random_indices = np.random.choice(len(synth_x_test), num_examples_to_display, replace=False)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Get original and predicted labels\n",
        "    original_label = synth_y_test[idx]\n",
        "    predicted_label = decoded_predictions[idx]\n",
        "\n",
        "    # Convert labels to human-readable strings\n",
        "    original_str = labels_to_string(original_label)\n",
        "    predicted_str = labels_to_string(predicted_label)\n",
        "\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(synth_x_test[idx].squeeze(), cmap='gray')\n",
        "    plt.title(f\"True: {original_str}\\nPred: {predicted_str}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "642a9723"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because the `blank_char` variable was not globally defined, causing a `NameError` within the `decode_batch_predictions` function. I will re-define `blank_char` globally at the beginning of the cell where it is first used to ensure its availability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "465b41d1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define blank_char globally as it's used in decode_batch_predictions\n",
        "blank_char = 10  # Represent 'blank' digit, since MNIST digits are 0-9\n",
        "\n",
        "# 1. Definisikan fungsi decode_batch_predictions\n",
        "def decode_batch_predictions(pred):\n",
        "    # Use ctc_decode to get the decoded sequences. `greedy=False` for beam search if needed,\n",
        "    # but for simplicity, `greedy=True` is often used first.\n",
        "    # The second return value is the log-probability of the sequence, which we don't need for this task.\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "\n",
        "    # Convert sparse tensor to dense numpy array. Pad with `blank_char` (10) if the decoded sequence is shorter than max_sequence_length\n",
        "    decoded_sequences = tf.sparse.to_dense(results, default_value=blank_char).numpy()\n",
        "    return decoded_sequences\n",
        "\n",
        "# Note: `max_sequence_length` (5) is already defined from previous steps."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1077a67"
      },
      "source": [
        "**Reasoning**:\n",
        "With `blank_char` now correctly defined and the `decode_batch_predictions` function ready, I will proceed to make predictions on the test set, decode them, map the decoded digits to characters, and finally visualize 10 random examples to demonstrate the model's performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feee3278"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2. Lakukan prediksi pada synth_x_test\n",
        "predictions = model.predict(synth_x_test)\n",
        "\n",
        "# 3. Gunakan fungsi decode_batch_predictions untuk mendekode predictions\n",
        "decoded_predictions = decode_batch_predictions(predictions)\n",
        "\n",
        "# 4. Definisikan pemetaan dari indeks digit ke karakter yang sesuai\n",
        "digit_to_char = {i: str(i) for i in range(10)}\n",
        "digit_to_char[blank_char] = '_'\n",
        "\n",
        "def labels_to_string(labels):\n",
        "    return ''.join([digit_to_char[digit] for digit in labels if digit != blank_char])\n",
        "\n",
        "# 5. Ambil 10 contoh acak dari set pengujian dan tampilkan\n",
        "print(\"Displaying 10 random examples from the test set:\\n\")\n",
        "\n",
        "num_examples_to_display = 10\n",
        "random_indices = np.random.choice(len(synth_x_test), num_examples_to_display, replace=False)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Get original and predicted labels\n",
        "    original_label = synth_y_test[idx]\n",
        "    predicted_label = decoded_predictions[idx]\n",
        "\n",
        "    # Convert labels to human-readable strings\n",
        "    original_str = labels_to_string(original_label)\n",
        "    predicted_str = labels_to_string(predicted_label)\n",
        "\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(synth_x_test[idx].squeeze(), cmap='gray')\n",
        "    plt.title(f\"True: {original_str}\\nPred: {predicted_str}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}